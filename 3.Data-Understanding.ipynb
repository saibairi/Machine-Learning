{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5ee381c-a5a7-4df2-b9f7-fe79df831e71",
   "metadata": {},
   "source": [
    "# Data Understanding\n",
    "\n",
    "While working with machine learning projects, usually we ignore two most important parts called mathematics and data. What makes data understanding a critical step in ML is its data driven approach. Our ML model will produce only as good or as bad results as the data we provided to it.\r\n",
    "\r\n",
    "Data understanding basically involves analyzing and exploring the data to identify any patterns or trends that may be present.\r\n",
    "\r\n",
    "The data understanding phase typically involves the following steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761e6622-ecd4-4da1-af46-05db76108100",
   "metadata": {},
   "source": [
    "1. Data Collection − This involves gathering the relevant data that you will be using for your analysis. The data can be collected from various sources such as databases, websites, and APIs.\n",
    "\n",
    "\n",
    "2. Data Cleaning − This involves cleaning the data by removing any irrelevant or duplicate data, and dealing with missing data values. The data should be formatted in a way that makes it easy to analyze.\n",
    "\n",
    "\n",
    "3. Data Exploration − This involves exploring the data to identify any patterns or trends that may be present. This can be done using various statistical techniques such as histograms, scatter plots, and correlation analysis.\n",
    "\n",
    "\n",
    "4. Data Visualization − This involves creating visual representations of the data to help you understand it better. This can be done using tools such as graphs, charts, and maps.\n",
    "\n",
    "\n",
    "5. Data Preprocessing − This involves transforming the data to make it suitable for use in machine learning algorithms. This can include scaling the data, transforming it into a different format, or reducing its dimensionality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423f5d13-e966-4e2a-8874-db810dd9ef79",
   "metadata": {},
   "source": [
    "# Understand the Data before Uploading It in ML Projects\n",
    "\n",
    "Understanding our data before uploading it into our ML project is important for several reasons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae6e764-3b3b-4e51-9290-2edaa0308f66",
   "metadata": {},
   "source": [
    "### Identify Data Quality Issues\n",
    "\n",
    "By understanding your data, you can identify data quality issues such as missing values, outliers, incorrect data types, and inconsistencies that can affect the performance of your ML model. By addressing these issues, you can improve the quality and accuracy of your model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f83c3d-116d-4d27-8669-7b5e76fea8e5",
   "metadata": {},
   "source": [
    "### Determine Data Relevance\n",
    "\n",
    "You can determine if the data you have collected is relevant to the problem you are trying to solve. By understanding your data, you can determine which features are important for your model and which ones can be ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a135172-8951-4458-827a-ed1d4b6a4ebc",
   "metadata": {},
   "source": [
    "### Select Appropriate ML Techniques\n",
    "\n",
    "Depending on the characteristics of your data, you may need to choose a particular ML technique or algorithm. For example, if your data is categorical, you may need to use classification techniques, while if your data is continuous, you may need to use regression techniques. Understanding your data can help you select the appropriate ML technique for your problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3f8b5d-2b1b-4c4b-9f08-db147e123b69",
   "metadata": {},
   "source": [
    "### Improve Model Performance\n",
    "\n",
    "By understanding your data, you can engineer new features, preprocess your data, and select the appropriate ML technique to improve the performance of your model. This can result in better accuracy, precision, recall, and F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a32fb3-ea0f-4693-8055-2fcb6f4bda0a",
   "metadata": {},
   "source": [
    "# Data Understanding with Statistics\n",
    "\n",
    "It would be good to understand the data before uploading it. We can understand the data by two ways, with statistics and with visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa662d4-f091-4bd2-ac08-c38a8ad5b0dc",
   "metadata": {},
   "source": [
    "# Looking at Raw Data\n",
    "\n",
    "The very first recipe is for looking at your raw data. It is important to look at raw data because the insight we will get after looking at raw data will boost our chances to better pre-processing as well as handling of data for ML projects.\n",
    "\n",
    "Following is a Python script implemented by using head() function of Pandas DataFrame on Pima Indians diabetes dataset to look at the first 10 rows to get better understanding of it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "363d24bd-6535-4e1d-b6e7-feac6315ba8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  DiabetesPedigreeFunction  \\\n",
      "0            6      148             72             35        0  33.6                     0.627   \n",
      "1            1       85             66             29        0  26.6                     0.351   \n",
      "2            8      183             64              0        0  23.3                     0.672   \n",
      "3            1       89             66             23       94  28.1                     0.167   \n",
      "4            0      137             40             35      168  43.1                     2.288   \n",
      "5            5      116             74              0        0  25.6                     0.201   \n",
      "6            3       78             50             32       88  31.0                     0.248   \n",
      "7           10      115              0              0        0  35.3                     0.134   \n",
      "8            2      197             70             45      543  30.5                     0.158   \n",
      "9            8      125             96              0        0   0.0                     0.232   \n",
      "\n",
      "   Age  Outcome  \n",
      "0   50        1  \n",
      "1   31        0  \n",
      "2   32        1  \n",
      "3   21        0  \n",
      "4   33        1  \n",
      "5   30        0  \n",
      "6   26        1  \n",
      "7   29        0  \n",
      "8   53        1  \n",
      "9   54        1  \n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "path = r\"C:\\Users\\SaiKiranByriKshema\\Documents\\PythonTutorial\\ML\\data-understanding.csv\"\n",
    "\n",
    "data = read_csv(path)\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168f41dc-4f11-4dde-9c62-7844bc914e73",
   "metadata": {},
   "source": [
    "# Checking Dimensions of Data\n",
    "\n",
    "It is always a good practice to know how much data, in terms of rows and columns, we are having for our ML project. The reasons behind are −\n",
    "\n",
    "1. Suppose if we have too many rows and columns then it would take long time to run the algorithm and train the model.\n",
    "\n",
    "\n",
    "2. Suppose if we have too less rows and columns then it we would not have enough data to well train the model.\n",
    "\n",
    "Following is a Python script implemented by printing the shape property on Pandas Data Frame. We are going to implement it on iris data set for getting the total number of rows and columns in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "304b986f-f188-42a7-adda-b9adbd0dbfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb31bebb-c2be-4e40-bb0c-e5ec51f31c15",
   "metadata": {},
   "source": [
    "# Getting Each Attribute’s Data Type\n",
    "\n",
    "It is another good practice to know data type of each attribute. The reason behind is that, as per to the requirement, sometimes we may need to convert one data type to another. For example, we may need to convert string into floating point or int for representing categorial or ordinal values. We can have an idea about the attribute’s data type by looking at the raw data, but another way is to use dtypes property of Pandas DataFrame. With the help of dtypes property we can categorize each attributes data type. It can be understood with the help of following Python script "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f501329c-4c1a-4077-8a57-360d499a857c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregnancies                   int64\n",
      "Glucose                       int64\n",
      "BloodPressure                 int64\n",
      "SkinThickness                 int64\n",
      "Insulin                       int64\n",
      "BMI                         float64\n",
      "DiabetesPedigreeFunction    float64\n",
      "Age                           int64\n",
      "Outcome                       int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7005f6-8731-4614-a257-c3c0db87d563",
   "metadata": {},
   "source": [
    "# Statistical Summary of Data\n",
    "\n",
    "We have discussed Python recipe to get the shape i.e. number of rows and columns, of data but many times we need to review the summaries out of that shape of data. It can be done with the help of describe() function of Pandas DataFrame that further provide the following 8 statistical properties of each & every data attribute −\n",
    "\n",
    "Count\n",
    "\n",
    "Mean\n",
    "\n",
    "Standard Deviation\n",
    "\n",
    "Minimum Value\n",
    "\n",
    "Maximum value\n",
    "\n",
    "25%\n",
    "\n",
    "Median i.e. 50%\n",
    "\n",
    "75%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8bb9e9f-50b6-4744-b96c-d8c2324b57b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin         BMI  \\\n",
      "count   768.000000  768.000000     768.000000     768.000000  768.000000  768.000000   \n",
      "mean      3.845052  120.894531      69.105469      20.536458   79.799479   31.992578   \n",
      "std       3.369578   31.972618      19.355807      15.952218  115.244002    7.884160   \n",
      "min       0.000000    0.000000       0.000000       0.000000    0.000000    0.000000   \n",
      "25%       1.000000   99.000000      62.000000       0.000000    0.000000   27.300000   \n",
      "50%       3.000000  117.000000      72.000000      23.000000   30.500000   32.000000   \n",
      "75%       6.000000  140.250000      80.000000      32.000000  127.250000   36.600000   \n",
      "max      17.000000  199.000000     122.000000      99.000000  846.000000   67.100000   \n",
      "\n",
      "       DiabetesPedigreeFunction         Age     Outcome  \n",
      "count                768.000000  768.000000  768.000000  \n",
      "mean                   0.471876   33.240885    0.348958  \n",
      "std                    0.331329   11.760232    0.476951  \n",
      "min                    0.078000   21.000000    0.000000  \n",
      "25%                    0.243750   24.000000    0.000000  \n",
      "50%                    0.372500   29.000000    0.000000  \n",
      "75%                    0.626250   41.000000    1.000000  \n",
      "max                    2.420000   81.000000    1.000000  \n"
     ]
    }
   ],
   "source": [
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11959c31-c0fa-4dce-a1e9-f3f0bc7c2f26",
   "metadata": {},
   "source": [
    "# Reviewing Class Distribution\n",
    "\n",
    "Class distribution statistics is useful in classification problems where we need to know the balance of class values. It is important to know class value distribution because if we have highly imbalanced class distribution i.e. one class is having lots more observations than other class, then it may need special handling at data preparation stage of our ML project. We can easily get class distribution in Python with the help of Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d18b4335-e7f5-4442-84da-50ebbfe809cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome\n",
      "0    500\n",
      "1    268\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "count_class = data.groupby('Outcome').size()\n",
    "print(count_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ed99e2-bfaf-4f3f-8096-6940b6077fed",
   "metadata": {},
   "source": [
    "# Reviewing Correlation between Attributes\n",
    "\n",
    "The relationship between two variables is called correlation. In statistics, the most common method for calculating correlation is Pearson’s Correlation Coefficient. It can have three values as follows −\n",
    "\n",
    "1. Coefficient value = 1 − It represents full positive correlation between variables.\n",
    "\n",
    "\n",
    "2. Coefficient value = -1 − It represents full negative correlation between variables.\n",
    "\n",
    "\n",
    "3. Coefficient value = 0 − It represents no correlation at all between variables.\n",
    "\n",
    "It is always good for us to review the pairwise correlations of the attributes in our dataset before using it into ML project because some machine learning algorithms such as linear regression and logistic regression will perform poorly if we have highly correlated attributes. In Python, we can easily calculate a correlation matrix of dataset attributes with the help of corr() function on Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e58ae1bd-c281-4291-982d-8a51659338e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "Pregnancies                      1.00     0.13           0.14          -0.08    -0.07  0.02   \n",
      "Glucose                          0.13     1.00           0.15           0.06     0.33  0.22   \n",
      "BloodPressure                    0.14     0.15           1.00           0.21     0.09  0.28   \n",
      "SkinThickness                   -0.08     0.06           0.21           1.00     0.44  0.39   \n",
      "Insulin                         -0.07     0.33           0.09           0.44     1.00  0.20   \n",
      "BMI                              0.02     0.22           0.28           0.39     0.20  1.00   \n",
      "DiabetesPedigreeFunction        -0.03     0.14           0.04           0.18     0.19  0.14   \n",
      "Age                              0.54     0.26           0.24          -0.11    -0.04  0.04   \n",
      "Outcome                          0.22     0.47           0.07           0.07     0.13  0.29   \n",
      "\n",
      "                          DiabetesPedigreeFunction   Age  Outcome  \n",
      "Pregnancies                                  -0.03  0.54     0.22  \n",
      "Glucose                                       0.14  0.26     0.47  \n",
      "BloodPressure                                 0.04  0.24     0.07  \n",
      "SkinThickness                                 0.18 -0.11     0.07  \n",
      "Insulin                                       0.19 -0.04     0.13  \n",
      "BMI                                           0.14  0.04     0.29  \n",
      "DiabetesPedigreeFunction                      1.00  0.03     0.17  \n",
      "Age                                           0.03  1.00     0.24  \n",
      "Outcome                                       0.17  0.24     1.00  \n"
     ]
    }
   ],
   "source": [
    "from pandas import set_option\n",
    "set_option('display.width', 100)\n",
    "set_option('display.precision', 2)\n",
    "correlations = data.corr(method='pearson')\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a97f8f-b846-4c07-95a3-747773592875",
   "metadata": {},
   "source": [
    "# Reviewing Skew of Attribute Distribution\n",
    "Skewness may be defined as the distribution that is assumed to be Gaussian but appears distorted or shifted in one direction or another, or either to the left or right. Reviewing the skewness of attributes is one of the important tasks due to following reasons −\n",
    "\n",
    "1. Presence of skewness in data requires the correction at data preparation stage so that we can get more accuracy from our model.\n",
    "\n",
    "\n",
    "2. Most of the ML algorithms assumes that data has a Gaussian distribution i.e. either normal of bell curved data.\n",
    "\n",
    "In Python, we can easily calculate the skew of each attribute by using skew() function on Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7b2dc0c-e2e1-4bd1-893a-72605fbc01bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregnancies                 0.90\n",
      "Glucose                     0.17\n",
      "BloodPressure              -1.84\n",
      "SkinThickness               0.11\n",
      "Insulin                     2.27\n",
      "BMI                        -0.43\n",
      "DiabetesPedigreeFunction    1.92\n",
      "Age                         1.13\n",
      "Outcome                     0.64\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(data.skew())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658bc50a-d2a2-4ecb-93a4-92e493b58cce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
