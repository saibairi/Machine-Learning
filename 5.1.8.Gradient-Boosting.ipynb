{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa4cbd01-4b69-4ba2-b852-13e7d117897a",
   "metadata": {},
   "source": [
    "# Machine Learning - Gradient Boosting\n",
    "\n",
    "Gradient Boosting Machines (GBM) is a powerful machine learning technique that is widely used for building predictive models. It is a type of ensemble method that combines the predictions of multiple weaker models to create a stronger and more accurate model.\r\n",
    "\r\n",
    "GBM is a popular choice for a wide range of applications, including regression, classification, and ranking problems. Let's understand the workings of GBM and how it can be used in machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8648e6a-3f54-4880-b461-18ec90032319",
   "metadata": {},
   "source": [
    "# What is a Gradient Boosting Machine (GBM)?\n",
    "\n",
    "GBM is an iterative machine learning algorithm that combines the predictions of multiple decision trees to make a final prediction.\n",
    "\n",
    "The algorithm works by training a sequence of decision trees, each of which is designed to correct the errors of the previous tree.\n",
    "\n",
    "In each iteration, the algorithm identifies the samples in the dataset that are most difficult to predict and focuses on improving the model's performance on these samples.\n",
    "\n",
    "This is achieved by fitting a new decision tree that is optimized to reduce the errors on the difficult samples. The process continues until a specified stopping criteria is met, such as reaching a certain level of accuracy or the maximum number of iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b42750-e9f6-4ef2-b766-85193d2fd134",
   "metadata": {},
   "source": [
    "# How Does a Gradient Boosting Machine Work?\n",
    "\n",
    "The basic steps involved in training a GBM model are as follows −\n",
    "\n",
    "#### Initialize the model:\n",
    "\n",
    "The algorithm starts by creating a simple model, such as a single decision tree, to serve as the initial model.\n",
    "\n",
    "\n",
    "#### Calculate residuals:\n",
    "\n",
    "The initial model is used to make predictions on the training data, and the residuals are calculated as the differences between the predicted values and the actual values.\n",
    "\n",
    "\n",
    "#### Train a new model:\n",
    "\n",
    "A new decision tree is trained on the residuals, with the goal of minimizing the errors on the difficult samples.\n",
    "\n",
    "\n",
    "#### Update the model:\n",
    "\n",
    "The predictions of the new model are added to the predictions of the previous model, and the residuals are recalculated based on the updated predictions.\n",
    "\n",
    "\n",
    "Repeat − Steps 3-4 are repeated until a specified stopping criteria is met.\n",
    "\n",
    "\n",
    "GBM can be further improved by introducing regularization techniques, such as L1 and L2 regularization, to prevent overfitting. Additionally, GBM can be extended to handle categorical variables, missing data, and multi-class classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5992a571-755f-4725-be00-fb1e0b733cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the breast cancer dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model using GradientBoostingClassifier\n",
    "model = GradientBoostingClassifier(n_estimators=100, max_depth=3, learning_rate=0.1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae48da5c-c23a-46b8-af13-048e34787371",
   "metadata": {},
   "source": [
    "# Advantages of Using Gradient Boosting Machines\n",
    "\n",
    "There are several advantages of using GBM in machine learning −\n",
    "\n",
    "\n",
    "#### High accuracy:\n",
    "\n",
    "GBM is known for its high accuracy, as it combines the predictions of multiple weaker models to create a stronger and more accurate model.\n",
    "\n",
    "\n",
    "#### Robustness:\n",
    "\n",
    "GBM is robust to outliers and noisy data, as it focuses on improving the model's performance on the most difficult samples.\n",
    "\n",
    "\n",
    "#### Flexibility:\n",
    "\n",
    "GBM can be used for a wide range of applications, including regression, classification, and ranking problems.\n",
    "\n",
    "\n",
    "#### Interpretability:\n",
    "\n",
    "GBM provides insights into the importance of different features in making predictions, which can be useful for understanding the underlying factors driving the predictions.\n",
    "\n",
    "\n",
    "#### Scalability:\n",
    "\n",
    "GBM can handle large datasets and can be parallelized to accelerate the training process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8800201-05b1-4ca9-a93e-6a5cf6055add",
   "metadata": {},
   "source": [
    "# Limitations of Gradient Boosting Machines\n",
    "\n",
    "There are also some limitations to using GBM in machine learning −\n",
    "\n",
    "\n",
    "#### Training time:\n",
    "\n",
    "GBM can be computationally expensive and may require a significant amount of training time, especially when working with large datasets.\n",
    "\n",
    "\n",
    "#### Hyperparameter tuning:\n",
    "\n",
    "GBM requires careful tuning of hyperparameters, such as the learning rate, number of trees, and maximum depth, to achieve optimal performance.\n",
    "\n",
    "\n",
    "#### Black box model:\n",
    "\n",
    "GBM can be difficult to interpret, as the final model is a combination of multiple decision trees and may not provide clear insights into the underlying factors driving the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f289e8f-b5a1-4b3d-a30b-1756c8492859",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
